---
title: 记一次由于网关重试导致的生产事故
tags: 
   - spring
   - 经验
---


### 前言

简单介绍一下背景,我们组是做支付清算的.主要业务是划扣,出入金,结算,报表 这些.

刚起步半年多,用户规模只有不到20w.这是前提.

最早发现问题的是客服MM.周五晚上八点左右.有很多账期日的客户向客服投诉,他们绑定的银行卡被多划扣了一笔钱.

原本该从用户卡里划2000块 或者3000块,统统加倍,变成4000块 或者 6000块.卡里钱不够的就被三光了.

这是个很严重的问题.就说一下我们是如何处理这次问题的吧.

<!--more-->
#### 处理线上问题

**首先.我们关闭了自动划扣功能**.已知划扣功能有问题的情况下还继续从用户卡里划钱就太冒险了.



**然后是问题的影响范围**.通过查询流水记录我们知道,被多次划扣的用户的账期日都是周五当天.略微松了一口气.我们整理了一份名单.通过这份名单可以给被多次划扣的用户退款.

有一些用户卡里正好没有钱,所以幸免了.其中有一部分用户的名字 经常 在催收mm的咆哮中出现.但是今天不太一样,他们的名字看起来特别亲切.



**接下来是找到问题的原因.** 直接原因是,因为Zuul网关重试导致划扣api被调用了2次.从而导致用户被划了2笔钱.

解释一下网关重试为什么会导致多次划扣.我们服务端是springcloud 微服务架构,自动划扣是由调度服务发起的.调度服务的架构大概是这样:

![](https://gitee.com/minagamiyuki/picgo-gitee/raw/master/images/截屏2020-02-15下午4.59.01.png)

众所周知微服务互相调用需要走网关.通过网关调用微服务有个机制是,如果一段时间被调用的服务没有响应,那么网关会自动发起重试.默认的周期大概是30秒.

从划扣服务的接口日志来看,是因为接口被多次调用.导致重复划扣.再看调度服务的日志,只发起了一次划扣请求.那么问题就只能是由于网关重试导致的了.

**剩下的是验证 & 解决问题.** 

知道问题原因以后,处理起来就简单啦.

* 验证 : 写个api,内部 `Thread.sleep()` 阻塞30秒,打印日志.通过调度中心调用它.看看是否会出现调用2次的情况.验证成功.
* 解决问题 : 通过Redis为划扣操作加上互斥锁 .保证同一个用户不会被重复划扣.
* 当然,挨骂肯定是少不了的.关键还是要吸取教训,不能被一块石头绊倒2次.


